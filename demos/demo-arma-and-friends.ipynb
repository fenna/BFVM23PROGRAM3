{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb415d17-1d30-4e5a-8bc1-2676e7ca7ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import datetime\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import neurokit2 as nk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0165a5ca-bdca-4695-adfe-40ae909caa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_x_axis(ax):\n",
    "    years = mdates.YearLocator()   # every year\n",
    "    months = mdates.MonthLocator()  # every month\n",
    "    yearsFmt = mdates.DateFormatter('%Y')\n",
    "    ax.xaxis.set_major_locator(years)\n",
    "    ax.xaxis.set_major_formatter(yearsFmt)\n",
    "    ax.xaxis.set_minor_locator(months)\n",
    "    ax.tick_params(axis='x', labelrotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2ff6ee-d910-47a0-8ccc-5c1dcb7f376f",
   "metadata": {},
   "source": [
    "# ARMA and friends\n",
    "\n",
    "The models we describe in this notebook can be called *classical models*, as they have been worked out at the beginnig of the previous century and therefore have a longer tradition than more recent statistical models.\n",
    "\n",
    "A time-series process can be either stationary or non-stationary. Stationarity is defined by the following three characteristics:\n",
    "\n",
    "1. Finite *variation*\n",
    "2. Constant *mean*\n",
    "3. Constant *variation*\n",
    "\n",
    "Many time-series exhibit trends and seasonality, while many others assume stationarity. If a time-series is stationary, its mean and standard deviation stays constant over time. This implies that the time-series has no trend and no cyclic variability. Therefore the removal of irregular components, trends, and seasonal fluctuations is an intrinsic aspect of applying classical models. The models then forecast what's left after this removal.\n",
    "\n",
    "## Dickey-Fuller test\n",
    "To check for stationarity, we can use the [Dickey-Fuller Test](https://en.wikipedia.org/wiki/Dickey%E2%80%93Fuller_test). This test specifically checks for the presence of a unit root in the time series, which would indicate non-stationarity. A unit root means the series has a trend and is not stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96b41c3-f5dc-4984-8104-a8b468e4942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_data = nk.ecg_simulate(duration=10)\n",
    "nk.signal_plot(ecg_data, figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efd9b88-9d21-43e7-ae14-6c7b0c8ac567",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = adfuller(ecg_data)\n",
    "\n",
    "# Extract results\n",
    "print(f'ADF Statistic: {result[0]}')\n",
    "print(f'p-value: {result[1]}')\n",
    "print(f'Critical Values: {result[4]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eb6697-c822-4c07-8f9a-aac6484222f9",
   "metadata": {},
   "source": [
    "We have a very small `p-value`, which means that our data is stationary. That resonates with the three characteristics of stationary data. Lets' do the same for more random data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e8b865-ac78-4030-b357-ed16d7912a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random_walk = np.random.normal(loc=0, scale=1, size=1000).cumsum()\n",
    "random_walk_series = pd.Series(random_walk)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(random_walk_series, color='purple')\n",
    "plt.title('Random Walk (Non-Stationary Data)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79526ff-85e7-4acc-a85f-8abbf61aa070",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = adfuller(random_walk_series)\n",
    "\n",
    "print(f'ADF Statistic: {result[0]}')\n",
    "print(f'p-value: {result[1]}')\n",
    "print(f'Critical Values: {result[4]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be19ded0-0257-4584-9e16-090825fa393e",
   "metadata": {},
   "source": [
    "The ADF statistic is higher than the critical values at the 1%, 5%, and 10% levels. Since the p-value is much greater than 0.05, we fail to reject the null hypothesis that the data has a unit root. Therefore, the data is non-stationary, which is expected since we generated it as a random walk (a typical non-stationary series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a27f82f-df98-4ee5-bfaa-414feca6d193",
   "metadata": {},
   "source": [
    "## Moving Average\n",
    "\n",
    "The *Moving Average* (MA), the unweighted mean over a period of $k$ points, is defined as follows:\n",
    "\n",
    "$$\n",
    "MA = \\frac{1}{k}\\Sigma_{i=1}^{k}x_i\n",
    "$$ \n",
    "\n",
    "where $x_i$ is the observed time-series.\n",
    "\n",
    "The MA can be used to smooth out a time-series, thereby removing noise and periodic fluctuations that occur in the short term, effectively working as a low-pass filter. We have seen this in our [`demo_univariate_modelling`-notebook](demo_univariate_modelling.ipynb')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d45b9f-8fe9-447c-9ea1-3e0a72ccc942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/btc.csv', names=['date','value'], skiprows=1, parse_dates=[0])\n",
    "df['avg'] = df['value'].rolling(30).mean()\n",
    "#df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d481527d-f85d-4015-96c8-de81877d5a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "format_x_axis(ax)\n",
    "ax.plot(df['date'], df['value'], label='value')\n",
    "ax.plot(df['date'], df['avg'], label='rolling mean')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ccbfe6-8c88-437d-bcf8-e7b689bc7693",
   "metadata": {},
   "source": [
    "We can also use MA to forecast into the future as well. The time-series is a linear regression of the current value of the series against observed values. For this to work, we can use the [*Autoregressive Model*](https://en.wikipedia.org/wiki/Autoregressive_model), which regresses the variable on its own lagged values: the current value of the value is driven by immediately preceding values using a linear combination. This way we get an *autoregressiveâ€“moving-average* or ARMA-model. \n",
    "\n",
    "The Autoregressive (AR) part of the ARMA model uses the relationship between an observation and a number of lagged (previous) observations to predict future values. The Moving Average (MA) part of the ARMA model uses the dependency between an observation and a residual error from a moving average model applied to lagged observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590ef6b9-117b-4291-abc0-518d32e16001",
   "metadata": {},
   "source": [
    "## ARMA model\n",
    "The ARMA-model consists of two types of lagged values, one for the autoregressive component and the other fot he moving average component. Therefore, we write $ARMA(p,q)$, where $p$ indicates the order of the autoregression, and $q$ the order of the moving average. Thus\n",
    "\n",
    "$$\n",
    "ARMA(p,q):x_t = c + \\epsilon_t + \\Sigma_{i=1}^{p}\\phi_ix_{t-i} + \\Sigma_{i=0}^{q}\\Phi_i\\epsilon_{t-i}\n",
    "$$\n",
    "\n",
    "where  $c$ is a constant, $\\phi_i$ and $\\Phi_i$ are *model parameters* and $\\epsilon_t$ represents noise. ARMA assumes that the series is stationary. \n",
    "\n",
    "To demonstrate ARMA in statsmodels, we need to use the [`ARIMA`-class](https://www.statsmodels.org/stable/generated/statsmodels.tsa.arima.model.ARIMA.html), with the differencing-parameter set to zero (0). We'll get to this in a moment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73f6b36-2e19-4192-8aaa-ce7372e6bd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we define a method to plot our results.\n",
    "\n",
    "def plot_model_results(ax, data, models=[], names=[], colors=[], steps=30, color='red'):\n",
    "    assert len(models) == len(names)\n",
    "    assert len(models) == len(colors)\n",
    "    ax.plot(data, label='Observed Data', color='blue')\n",
    "    ax.axvline(n, color='gray', linestyle='dotted', label='Forecast Start')\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        forecast = model.get_forecast(steps=steps)\n",
    "        preds = forecast.predicted_mean    \n",
    "        conf = forecast.conf_int()\n",
    "        idx = np.arange(n, n + steps)\n",
    "        \n",
    "        #plot the forecasts:\n",
    "        ax.plot(idx, preds, label=f\"{names[i]} Forecast\", color=colors[i], linestyle='dashed')\n",
    "        # Plot the confidence Intervals\n",
    "        ax.fill_between(idx, conf[:, 0], conf[:, 1], color=colors[i], alpha=0.2)\n",
    "    \n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e54fa09-fc50-4991-841b-0aa2c003ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate some seasonal data (sinusoidal with noise)\n",
    "np.random.seed(42)\n",
    "seasonality = 20 # 20-period seasonality\n",
    "n = 100\n",
    "x = np.arange(n)\n",
    "seasonal_data = 10 * np.sin(2 * np.pi * x / seasonality) + np.random.normal(0, 2, size=n)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d82d850-794a-4e87-9ddf-573314d05b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "arma_model = sm.tsa.ARIMA(seasonal_data, order=(2, 0, 1))\n",
    "arma_results = arma_model.fit()\n",
    "arma_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1f4fd1-2a82-4b3b-b670-e6aa96867b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arma_results.params[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aec347-c60b-49f9-8df9-cf589dd63b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(12,6))\n",
    "plot_model_results(ax, seasonal_data, models=[arma_results], names=['ARMA'], colors=['red'])\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674510ea-cdf6-4c2a-8ddf-9708c59eda47",
   "metadata": {},
   "source": [
    "## The ARIMA model\n",
    "\n",
    "A generalisation of the ARMA model is the Autoregressive *Integrated* Moving Average model. It is especially used for non-stationary data, for it includes data pre-processing step to make the data more stationary. This is done by replacing values by subtracting the immediate past values, a transformation called *differencing*. The model integration is parametrized by $d$, which is the number of times differences have been taken between current and previous values. So, an ARIMA model is capable of capturing trands but not seasonality.\n",
    "\n",
    "Note that in te cell below we use the same class as above, only with different values for the `order`-parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f525897e-5721-4944-bd43-8b51c7fc25c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_model = sm.tsa.ARIMA(seasonal_data, order=(2, 1, 1))\n",
    "arima_results = arima_model.fit()\n",
    "arima_results.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c912d58-fd6a-4bd8-b841-ec8bfb9a9882",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(12,6))\n",
    "plot_model_results(ax, seasonal_data, models=[arma_results, arima_results], names=['ARMA', 'ARIMA'], colors=['red','green'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a44a43-6f4e-4ca8-92f0-640a10c7047b",
   "metadata": {},
   "source": [
    "## The SARIMA model\n",
    "\n",
    "To account for the seasonality of the data, we have another generalisation of the ARMA model, called SARIMA (we didn't make this up). SARIMO models are usually stated as $ARIMA(p,d,q)(P,D,Q)m$, where\n",
    "\n",
    "- $m$ denotes the number of periods in a season\n",
    "- $P,D,Q$ parametrize the autoregressive, integration, and moving average component of the *sesonal part*\n",
    "- $p,d,q$ are the parameters of the ARIMA-part, that we discussed above.\n",
    "\n",
    "For SARIMA, we have another class that we can use, [`SARIMAX`](https://www.statsmodels.org/stable/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html#statsmodels.tsa.statespace.sarimax.SARIMAX)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f616d7-b53e-45f4-9f92-dd973e9009cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_model = sm.tsa.SARIMAX(seasonal_data, order=(2, 1, 1), seasonal_order=(1, 1, 1, 20))\n",
    "sarima_results = sarima_model.fit()\n",
    "sarima_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf76b64-dd95-41ef-a77d-a5e479c27264",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(12,6))\n",
    "plot_model_results(ax, seasonal_data, \n",
    "                   models=[arma_results, arima_results, sarima_results],\n",
    "                   names=['ARMA', 'ARIMA', 'SARIMA'],\n",
    "                   colors=['red', 'green', 'cyan'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddf8799-59c9-4cd4-a516-f1cf3ed35848",
   "metadata": {},
   "source": [
    "## Statistical interpretation\n",
    "\n",
    "From the plot above, you can conclude that for this seasonal data, SARIMA is by far the better predictor. Let's compare the three models numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d8b176-e442-4642-8e1c-2449fc7c430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison = pd.DataFrame({\n",
    "    \"ARMA\": [arma_results.aic, arma_results.bic, arma_results.params[-1], arma_results.pvalues.max()],\n",
    "    \"ARIMA\": [arima_results.aic, arima_results.bic, arima_results.params[-1], arima_results.pvalues.max()],\n",
    "    \"SARIMA\": [sarima_results.aic, sarima_results.bic, sarima_results.params[-1], sarima_results.pvalues.max()]\n",
    "}, index=[\"AIC\", \"BIC\", r\"$\\sigma^2$\", \"Max p-value\"])\n",
    "\n",
    "# Display the table\n",
    "model_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02acfc16-781f-4019-b846-95588f1bd85e",
   "metadata": {},
   "source": [
    "The relatively Low AIC and BIC suggest that the SARIMA-model fits well. Since its AIC and BIC values are the lowest, this model explains the data better than the others. A lower AIC/BIC usually means a better balance between fit and complexity. However, the high $\\sigma^2$ (3.3) suggests more residual variability. Finally, the high max p-value (0.99) is a red flag: it shows that at least on coefficient is statistically not significant. We can see this already in the summary above, actually: all the coefficients are way higher than 0.05.\n",
    "\n",
    "As an exercise, let's continue working on this last model, removing coefficients to see its AIC/BIC values improve (get lower). The coefficient with the highest p-value is `ma.S.L20`. Let's decrease this value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb05b0-8a9b-4bc5-a616-e9c1a6222b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima2_model = sm.tsa.SARIMAX(seasonal_data, order=(2, 1, 1), seasonal_order=(1, 1, 0, 20))\n",
    "sarima2_results = sarima_model.fit()\n",
    "sarima2_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f885930b-6b86-4929-9869-d1bbc26f0a60",
   "metadata": {},
   "source": [
    "As you see, this has no direct effect on the model. More research is necessary to see if we can improve on it; but that's left as an exercise to the reader ðŸ˜Ž."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
